import pandas as pd
import json
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError

# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
FILE_PATH = "/Users/seungwan/Downloads/ìœ ì¹˜ì›ë°ì´í„°250310.xlsx"  # íŒŒì¼ëª… ìˆ˜ì • ê°€ëŠ¥
CACHE_FILE = "/Users/seungwan/Downloads/address_cache.json"
BATCH_SIZE = 1000
MAX_WORKERS = 5

def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            print("âŒ ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ìƒˆ ìºì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤")
    return {}

def save_cache():
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(address_cache, f, ensure_ascii=False, indent=2)  # ensure_ascii=False ì¶”ê°€
    print(f"ğŸ’¾ ì£¼ì†Œ ìºì‹œ ì €ì¥ ì™„ë£Œ: {len(address_cache)}ê°œ ì£¼ì†Œ")

def preprocess_row(row):
    return {
        "name": str(row.get('ìœ ì¹˜ì›ëª…', '')).strip(),
        "address": str(row.get('ì£¼ì†Œ', '')).strip(),
        "latitude": None,
        "longitude": None
    }

def geocode_address(item):
    address = item["address"]
    if not address:
        return item
    
    if address in address_cache:
        item["latitude"], item["longitude"] = address_cache[address]
        return item
    
    for attempt in range(3):  # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
        try:
            location = geolocator.geocode(address)
            if location:
                item["latitude"], item["longitude"] = location.latitude, location.longitude
                address_cache[address] = (location.latitude, location.longitude)
                save_cache()
                return item
            break
        except (GeocoderTimedOut, GeocoderServiceError) as e:
            print(f"â³ ì¬ì‹œë„ {attempt + 1}/3: {address} ({e})")
            time.sleep(2 ** attempt)
    
    return item

def chunk_data(data_list, chunk_size):
    for i in range(0, len(data_list), chunk_size):
        yield data_list[i:i + chunk_size]

def process_data():
    print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    df = pd.read_excel(FILE_PATH, engine="openpyxl", header=2)
    df.rename(columns=lambda x: str(x).strip(), inplace=True)
    print("ğŸ“Œ ì»¬ëŸ¼ëª… í™•ì¸:", df.columns)
    
    kindergartens = [preprocess_row(row) for _, row in df.iterrows()]
    print(f"ì´ {len(kindergartens)}ê°œì˜ ìœ ì¹˜ì› ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    
    batches = list(chunk_data(kindergartens, BATCH_SIZE))
    all_results = []
    
    for batch_idx, batch in enumerate(batches, 1):
        print(f"\nâ³ ë°°ì¹˜ {batch_idx}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ í•­ëª©)")
        batch_results = []
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_item = {executor.submit(geocode_address, item): item for item in batch}
            
            for future in tqdm(as_completed(future_to_item), total=len(batch), desc=f"ë°°ì¹˜ {batch_idx} ì§€ì˜¤ì½”ë”©"):
                try:
                    result = future.result()
                    batch_results.append(result)
                except Exception as exc:
                    print(f'ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {exc}')
                
                if len(batch_results) % 100 == 0:
                    save_cache()
        
        all_results.extend(batch_results)
        save_cache()
    
    with open('kindergartens_with_coords_all.json', 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ì´ {len(all_results)}ê°œì˜ ìœ ì¹˜ì› ë°ì´í„°ë¥¼ ì¢Œí‘œ ì •ë³´ì™€ í•¨ê»˜ JSONìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ!")
    
    failed_count = sum(1 for k in all_results if k['address'] and k['latitude'] is None)
    success_rate = ((len(all_results) - failed_count) / len(all_results)) * 100
    print(f"ğŸ“Š ì£¼ì†Œ ë³€í™˜ ì„±ê³µë¥ : {success_rate:.2f}% ({len(all_results) - failed_count}/{len(all_results)})")

if __name__ == "__main__":
    geolocator = Nominatim(user_agent="kindergarten_locator", timeout=10)
    address_cache = load_cache()
    process_data()
